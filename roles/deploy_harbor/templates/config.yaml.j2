expose:
  type: ingress
  tls:
    enabled: true
    certSource: auto
    auto:
      commonName: "{{ harbor_domain }}"

externalURL: "https://{{ harbor_domain }}"

internalTLS:
  enabled: false
  certSource: "auto"

ipFamily:
  ipv6:
    enabled: false
  ipv4:
    enabled: true

persistence:
  enabled: true
  resourcePolicy: "keep"
  persistentVolumeClaim:
    # Disable auto-creation of PersistentVolumeClaim by specifying '-'
    # these will log to Swift / the Postgres DB
    registry:
      existingClaim: "-"
    chartmuseum:
      existingClaim: "-"
    jobservice:
      jobLog:
        existingClaim: "-"
    trivy:
      accessMode: ReadWriteOnce
      size: 20Gi
      annotations: {}

  # Define which storage backend is used for registry and chartmuseum to store
  # images and charts. Refer to
  # https://github.com/docker/distribution/blob/master/docs/configuration.md#storage
  # for the detail.
  imageChartStorage:
    disableredirect: false
    type: swift
    swift:
      authurl: "{{ openstack_credentials.clouds[cloud_name].auth.auth_url }}"
      username: "{{ openstack_credentials.clouds[cloud_name].auth.username }}"
      password: "{{ openstack_credentials.clouds[cloud_name].auth.password }}"
      container: containername
      region: "{{ openstack_credentials.clouds[cloud_name].region_name }}"
      tenantid: "{{ openstack_credentials.clouds[cloud_name].auth.project_id }}"
      domain: "{{ openstack_credentials.clouds[cloud_name].auth.user_domain_name }}"
      #chunksize: 5M
      #prefix:
      #tempurlcontainerkey: false
      #tempurlmethods:

logLevel: info
harborAdminPassword: "{{ harbor_admin_password }}"
secretKey: "{{ harbor_secret_key }}"

# Run the migration job via helm hook
enableMigrateHelmHook: true
portal:
  image:
    repository: goharbor/harbor-portal
    tag: dev
  replicas: 2

core:
  image:
    repository: goharbor/harbor-core
    tag: dev
  replicas: 2

jobservice:
  image:
    repository: goharbor/harbor-jobservice
    tag: dev
  replicas: 1
  jobLoggers:
    # - file
    - database
    # - stdout
  # The jobLogger sweeper duration (ignored if `jobLogger` is `stdout`)
  loggerSweeperDuration: 14 #days
  notification:
    webhook_job_max_retry: 3
    webhook_job_http_client_timeout: 3 # in seconds

registry:
  registry:
    image:
      repository: goharbor/registry-photon
      tag: dev
  controller:
    image:
      repository: goharbor/harbor-registryctl
      tag: dev

  replicas: 2
  credentials:
    username: "{{ harbor_username }}"
    password: "{{ harbor_user_password }}"
  upload_purging:
    enabled: true
    # remove files in _upload directories which exist for a period of time, default is one week.
    age: 168h
    # the interval of the purge operations
    interval: 24h
    dryrun: false

chartmuseum:
  enabled: false
  image:
    repository: goharbor/chartmuseum-photon
    tag: dev
  replicas: 1
  revisionHistoryLimit: 10

trivy:
  enabled: true
  image:
    repository: goharbor/trivy-adapter-photon
    tag: dev
  replicas: 2
  # debugMode the flag to enable Trivy debug mode with more verbose scanning log
  debugMode: false
  # vulnType a comma-separated list of vulnerability types. Possible values are `os` and `library`.
  vulnType: "os,library"
  # severity a comma-separated list of severities to be checked
  severity: "UNKNOWN,LOW,MEDIUM,HIGH,CRITICAL"
  # ignoreUnfixed the flag to display only fixed vulnerabilities
  ignoreUnfixed: false
  # insecure the flag to skip verifying registry certificate
  insecure: false
  # Comma-separated list of what security issues to detect. Possible values are `vuln`, `config` and `secret`. Defaults to `vuln`.
  securityCheck: "vuln"
notary:
  enabled: false

database:
  # if external database is used, set "type" to "external"
  # and fill the connection informations in "external" section
  type: external
    # set the service account to be used, default if left empty
    serviceAccountName: ""
    # mount the service account token
    automountServiceAccountToken: false
    image:
      repository: goharbor/harbor-db
      tag: dev
    # The initial superuser password for internal database
    password: "changeit"
    # The size limit for Shared memory, pgSQL use it for shared_buffer
    # More details see:
    # https://github.com/goharbor/harbor/issues/15034
    shmSizeLimit: 512Mi
    # resources:
    #  requests:
    #    memory: 256Mi
    #    cpu: 100m
    nodeSelector: {}
    tolerations: []
    affinity: {}
    ## The priority class to run the pod as
    priorityClassName:
    initContainer:
      migrator: {}
      # resources:
      #  requests:
      #    memory: 128Mi
      #    cpu: 100m
      permissions: {}
      # resources:
      #  requests:
      #    memory: 128Mi
      #    cpu: 100m
  external:
    host: "{{ db_host_name }}"
    port: "5432"
    username: "{{ postgres_username }}"
    password: "{{ postgres_password }}"
    coreDatabase: "registry"
    notaryServerDatabase: "notary_server"
    notarySignerDatabase: "notary_signer"
    # "disable" - No SSL
    # "require" - Always SSL (skip verification)
    # "verify-ca" - Always SSL (verify that the certificate presented by the
    # server was signed by a trusted CA)
    # "verify-full" - Always SSL (verify that the certification presented by the
    # server was signed by a trusted CA and the server host name matches the one
    # in the certificate)
    sslmode: "require"

redis:
  # if external Redis is used, set "type" to "external"
  # and fill the connection informations in "external" section
  type: external
  external:
    addr: "{{ redis_service.resources[0].spec.clusterIP }}"
    sentinelMasterSet: "mymaster"
    password: "{{ redis_password }}"

exporter:
  replicas: 1
  image:
    repository: goharbor/harbor-exporter
    tag: dev

metrics:
  enabled: false
  core:
    path: /metrics
    port: 8001
  registry:
    path: /metrics
    port: 8001
  jobservice:
    path: /metrics
    port: 8001
  exporter:
    path: /metrics
    port: 8001
  ## Create prometheus serviceMonitor to scrape harbor metrics.
  ## This requires the monitoring.coreos.com/v1 CRD. Please see
  ## https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/user-guides/getting-started.md  ##
  serviceMonitor:
    enabled: false
    additionalLabels: {}
    # Scrape interval. If not set, the Prometheus default scrape interval is used.
    interval: ""
    # Metric relabel configs to apply to samples before ingestion.
    metricRelabelings:
      []
      # - action: keep
      #   regex: 'kube_(daemonset|deployment|pod|namespace|node|statefulset).+'
      #   sourceLabels: [__name__]
    # Relabel configs to apply to samples before ingestion.
    relabelings:
      []
      # - sourceLabels: [__meta_kubernetes_pod_node_name]
      #   separator: ;
      #   regex: ^(.*)$
      #   targetLabel: nodename
      #   replacement: $1
      #   action: replace

trace:
  enabled: false
  # trace provider: jaeger or otel
  # jaeger should be 1.26+
  provider: jaeger
  # set sample_rate to 1 if you wanna sampling 100% of trace data; set 0.5 if you wanna sampling 50% of trace data, and so forth
  sample_rate: 1
  # namespace used to differentiate different harbor services
  # namespace:
  # attributes is a key value dict contains user defined attributes used to initialize trace provider
  # attributes:
  #   application: harbor
  jaeger:
    # jaeger supports two modes:
    #   collector mode(uncomment endpoint and uncomment username, password if needed)
    #   agent mode(uncomment agent_host and agent_port)
    endpoint: http://hostname:14268/api/traces
    # username:
    # password:
    # agent_host: hostname
    # export trace data by jaeger.thrift in compact mode
    # agent_port: 6831
  otel:
    endpoint: hostname:4318
    url_path: /v1/traces
    compression: false
    insecure: true
    timeout: 10s

# cache layer configurations
# if this feature enabled, harbor will cache the resource
# `project/project_metadata/repository/artifact/manifest` in the redis
# which help to improve the performance of high concurrent pulling manifest.
cache:
  # default is not enabled.
  enabled: true
  # default keep cache for one day.
  expireHours: 24